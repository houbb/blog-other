import{_ as e}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as i,a,o as n}from"./app-uJE4P3e0.js";const l={};function t(d,s){return n(),i("div",null,s[0]||(s[0]=[a(`<h1 id="模型服务" tabindex="-1"><a class="header-anchor" href="#模型服务"><span>模型服务</span></a></h1><h2 id="获取代码" tabindex="-1"><a class="header-anchor" href="#获取代码"><span>获取代码</span></a></h2><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">git</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> clone</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> https://github.com/WisdomShell/llama_cpp_for_codeshell.git</span></span>
<span class="line"><span style="--shiki-light:#0184BC;--shiki-dark:#56B6C2;">cd</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> llama_cpp_for_codeshell</span></span>
<span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">make</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="报错1" tabindex="-1"><a class="header-anchor" href="#报错1"><span>报错1</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>Command &#39;make&#39; not found, but can be installed with:</span></span>
<span class="line"><span>sudo apt install make        # version 4.3-4.1build1, or</span></span>
<span class="line"><span>sudo apt install make-guile  # version 4.3-4.1build1</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>按照提示，安装 make</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">sudo</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> apt</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> install</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> make</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h3 id="报错2" tabindex="-1"><a class="header-anchor" href="#报错2"><span>报错2</span></a></h3><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>I LDFLAGS:</span></span>
<span class="line"><span>/bin/sh: 1: cc: not found</span></span>
<span class="line"><span>I CC:</span></span>
<span class="line"><span>/bin/sh: 1: g++: not found</span></span>
<span class="line"><span>I CXX:</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>我们安装 gcc 和 g++</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>sudo apt update</span></span>
<span class="line"><span>sudo apt install gcc</span></span>
<span class="line"><span>sudo apt install g++</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>安装完成后，重新执行 make，等待编译完成。</p><h2 id="下载模型" tabindex="-1"><a class="header-anchor" href="#下载模型"><span>下载模型</span></a></h2><p>在 <a href="https://huggingface.co/WisdomShell/CodeShell-7B-Chat-int4/blob/main/codeshell-chat-q4_0.gguf" target="_blank" rel="noopener noreferrer">Hugging Face Hub</a></p><p>将模型下载到本地后，将模型放置在以上代码中的 llama_cpp_for_codeshell/models 路径，即可从本地加载模型。</p><p>下载后方法入到 <code>\\\\wsl.localhost\\Ubuntu\\home\\houbinbin\\ai\\llama_cpp_for_codeshell\\models</code> 目录下。</p><h2 id="部署模型" tabindex="-1"><a class="header-anchor" href="#部署模型"><span>部署模型</span></a></h2><p>使用llama_cpp_for_codeshell项目中的server命令即可提供API服务。</p><div class="language-sh line-numbers-mode" data-highlighter="shiki" data-ext="sh" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#4078F2;--shiki-dark:#61AFEF;">./server</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> -m</span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;"> ./models/codeshell-chat-q4_0.gguf</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --host</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 127.0.0.1</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> --port</span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;"> 18080</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><p>启动成功日志：</p><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>..............................................................................................</span></span>
<span class="line"><span>llama_new_context_with_model: n_ctx      = 8192</span></span>
<span class="line"><span>llama_new_context_with_model: freq_base  = 10000.0</span></span>
<span class="line"><span>llama_new_context_with_model: freq_scale = 1</span></span>
<span class="line"><span>llama_new_context_with_model: kv self size  = 1344.00 MB</span></span>
<span class="line"><span>llama_new_context_with_model: compute buffer total size = 558.13 MB</span></span>
<span class="line"><span></span></span>
<span class="line"><span>llama server listening at http://127.0.0.1:18080</span></span>
<span class="line"><span></span></span>
<span class="line"><span>{&quot;timestamp&quot;:1697814840,&quot;level&quot;:&quot;INFO&quot;,&quot;function&quot;:&quot;main&quot;,&quot;line&quot;:1786,&quot;message&quot;:&quot;HTTP server listening&quot;,&quot;hostname&quot;:&quot;127.0.0.1&quot;,&quot;port&quot;:18080}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h1 id="配置插件" tabindex="-1"><a class="header-anchor" href="#配置插件"><span>配置插件</span></a></h1><h2 id="下载" tabindex="-1"><a class="header-anchor" href="#下载"><span>下载</span></a></h2><p>下载 idea 插件</p><blockquote><p><a href="https://github.com/WisdomShell/codeshell-intellij/releases/tag/v0.0.1" target="_blank" rel="noopener noreferrer">https://github.com/WisdomShell/codeshell-intellij/releases/tag/v0.0.1</a> 选择 【CodeShell-0.0.1.zip】</p></blockquote><p>idea 插件直接本地安装。</p><h2 id="配置-idea" tabindex="-1"><a class="header-anchor" href="#配置-idea"><span>配置 idea</span></a></h2><p>设置CodeShell大模型服务地址: 我们调整为 <a href="http://127.0.0.1:18080/completion" target="_blank" rel="noopener noreferrer">http://127.0.0.1:18080/completion</a><br> 配置是否自动触发代码补全建议<br> 配置补全的最大tokens数量<br> 配置问答的最大tokens数量</p><h1 id="测试效果" tabindex="-1"><a class="header-anchor" href="#测试效果"><span>测试效果</span></a></h1><h2 id="q1-你好-你会说中文吗" tabindex="-1"><a class="header-anchor" href="#q1-你好-你会说中文吗"><span>Q1 你好，你会说中文吗</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>您好，我是CodeShell，一个由北京大学知识计算实验室（KCL）开发的 AI 助手。我可以用中文与您交流。请问我有什么可以帮助您的吗？</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div></div></div><h2 id="q2-你的实现原理是什么-你和-chatgpt-的区别" tabindex="-1"><a class="header-anchor" href="#q2-你的实现原理是什么-你和-chatgpt-的区别"><span>Q2 你的实现原理是什么？你和 chatGPT 的区别</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>我是一个自然语言处理模型，我的实现原理是基于深度学习和强化学习。我使用了多种算法来训练自己的模型，包括循环神经网络（RNN）、卷积神经网络（CNN）、LSTM 和 Transformer 等。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>与 chatGPT 不同的是，我不是一个生成文本的 AI 助手。我的目标是根据用户的问题提供相关的回答和建议。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="q3-fastjson-序列化循环依赖-导致-oom。如何解决" tabindex="-1"><a class="header-anchor" href="#q3-fastjson-序列化循环依赖-导致-oom。如何解决"><span>Q3 fastjson 序列化循环依赖，导致 oom。如何解决</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>如果使用 FastJSON 序列化存在循环依赖的对象，可能会导致内存溢出（OOM）。这通常是由于 JSON 序列化时对对象进行深度复制导致的。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>为了解决这个问题，可以尝试以下方法：</span></span>
<span class="line"><span></span></span>
<span class="line"><span>1. 使用 Jackson 代替 FastJSON：Jackson 是目前最流行的 JSON 序列化库之一，它支持循环依赖的对象序列化和反序列化。可以使用 Jackson 的 \`ObjectMapper\` 类来进行 JSON 序列化和反序列化操作。</span></span>
<span class="line"><span>2. 使用自定义实现：如果无法避免循环依赖，可以考虑使用自定义实现来解决这个问题。例如，可以在序列化的过程中对循环依赖的对象进行处理，将它们转换为其他形式（如字符串），然后再进行 JSON 序列化和反序列化操作。</span></span>
<span class="line"><span>3. 使用第三方工具：如果你使用的场景比较特殊，可以考虑使用第三方工具来解决这个问题。例如，可以考虑使用 \`protostuff\`、\`kryo\` 等开源的序列化库来解决这个问题。这些库都支持循环依赖的对象序列化和反序列化操作。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>总之，解决循环依赖的 JSON 序列化问题需要根据具体的场景进行相应的设计和实现。</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="q4-可以通过指定属性来解决这个问题吗" tabindex="-1"><a class="header-anchor" href="#q4-可以通过指定属性来解决这个问题吗"><span>Q4 可以通过指定属性来解决这个问题吗</span></a></h2><div class="language- line-numbers-mode" data-highlighter="shiki" data-ext="" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span>是的，您可以通过指定特定的属性来解决这个问题。</span></span>
<span class="line"><span></span></span>
<span class="line"><span>在这种情况下，您可以尝试使用\`class\`属性来为元素添加一个自定义的类。例如：</span></span>
<span class="line"><span>This is my custom div element</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>可以发现，这个工具没有上下文记忆功能。</p><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h1><p><a href="https://github.com/WisdomShell/codeshell-intellij" target="_blank" rel="noopener noreferrer">https://github.com/WisdomShell/codeshell-intellij</a></p>`,40)]))}const r=e(l,[["render",t]]),o=JSON.parse('{"path":"/posts/windows/2023-10-20-01-windows-install-linux-02-ai.html","title":"windows linux 安装 ai 编码神器 codeshell 笔记","lang":"zh-CN","frontmatter":{"title":"windows linux 安装 ai 编码神器 codeshell 笔记","date":"2023-10-20T00:00:00.000Z","categories":["Windows"],"tags":["windows","linux","os","sh"],"published":true,"description":"模型服务 获取代码 报错1 按照提示，安装 make 报错2 我们安装 gcc 和 g++ 安装完成后，重新执行 make，等待编译完成。 下载模型 在 Hugging Face Hub 将模型下载到本地后，将模型放置在以上代码中的 llama_cpp_for_codeshell/models 路径，即可从本地加载模型。 下载后方法入到 \\\\\\\\wsl.l...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/blog-backend/posts/windows/2023-10-20-01-windows-install-linux-02-ai.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"windows linux 安装 ai 编码神器 codeshell 笔记"}],["meta",{"property":"og:description","content":"模型服务 获取代码 报错1 按照提示，安装 make 报错2 我们安装 gcc 和 g++ 安装完成后，重新执行 make，等待编译完成。 下载模型 在 Hugging Face Hub 将模型下载到本地后，将模型放置在以上代码中的 llama_cpp_for_codeshell/models 路径，即可从本地加载模型。 下载后方法入到 \\\\\\\\wsl.l..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-22T03:45:14.000Z"}],["meta",{"property":"article:tag","content":"windows"}],["meta",{"property":"article:tag","content":"linux"}],["meta",{"property":"article:tag","content":"os"}],["meta",{"property":"article:tag","content":"sh"}],["meta",{"property":"article:published_time","content":"2023-10-20T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-22T03:45:14.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"windows linux 安装 ai 编码神器 codeshell 笔记\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-10-20T00:00:00.000Z\\",\\"dateModified\\":\\"2025-08-22T03:45:14.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1755834314000,"updatedTime":1755834314000,"contributors":[{"name":"binbin.hou","username":"","email":"binbin.hou@huifu.com","commits":1}]},"readingTime":{"minutes":3.38,"words":1015},"filePathRelative":"posts/windows/2023-10-20-01-windows-install-linux-02-ai.md","localizedDate":"2023年10月20日","excerpt":"\\n<h2>获取代码</h2>\\n<div class=\\"language-sh line-numbers-mode\\" data-highlighter=\\"shiki\\" data-ext=\\"sh\\" style=\\"--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34\\"><pre class=\\"shiki shiki-themes one-light one-dark-pro vp-code\\"><code><span class=\\"line\\"><span style=\\"--shiki-light:#4078F2;--shiki-dark:#61AFEF\\">git</span><span style=\\"--shiki-light:#50A14F;--shiki-dark:#98C379\\"> clone</span><span style=\\"--shiki-light:#50A14F;--shiki-dark:#98C379\\"> https://github.com/WisdomShell/llama_cpp_for_codeshell.git</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#0184BC;--shiki-dark:#56B6C2\\">cd</span><span style=\\"--shiki-light:#50A14F;--shiki-dark:#98C379\\"> llama_cpp_for_codeshell</span></span>\\n<span class=\\"line\\"><span style=\\"--shiki-light:#4078F2;--shiki-dark:#61AFEF\\">make</span></span></code></pre>\\n<div class=\\"line-numbers\\" aria-hidden=\\"true\\" style=\\"counter-reset:line-number 0\\"><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div><div class=\\"line-number\\"></div></div></div>","autoDesc":true}');export{r as comp,o as data};
