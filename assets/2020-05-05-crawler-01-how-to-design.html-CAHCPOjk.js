import{_ as a}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as r,a as t,o as p}from"./app-uJE4P3e0.js";const n={};function o(h,e){return p(),r("div",null,e[0]||(e[0]=[t('<h1 id="创作背景" tabindex="-1"><a class="header-anchor" href="#创作背景"><span>创作背景</span></a></h1><p>其实在此之前，自己也尝试过做过尝试。</p><p>而且做了两次，最后因为没有成为一个可高度复用的框架，而逐渐失去维护。</p><p>本篇整理下成熟工具的长处，结合自己失败的经验，为设计一款简单灵活的爬虫打下基础。</p><h1 id="以前失败的教训" tabindex="-1"><a class="header-anchor" href="#以前失败的教训"><span>以前失败的教训</span></a></h1><h2 id="暂停的工具" tabindex="-1"><a class="header-anchor" href="#暂停的工具"><span>暂停的工具</span></a></h2><p><a href="https://github.com/houbb/crawl" target="_blank" rel="noopener noreferrer">crawl</a></p><p><a href="https://github.com/houbb/poseidon.git" target="_blank" rel="noopener noreferrer">poseidon</a></p><h2 id="设计理念" tabindex="-1"><a class="header-anchor" href="#设计理念"><span>设计理念</span></a></h2><p>为了初期的快速迭代，使用<strong>单个模块</strong>。</p><p>对于页面等，初期不要求。</p><p>初期可以只考虑单机，后期初步加入分布式的设计。（要有预留）</p><h2 id="依赖框架" tabindex="-1"><a class="header-anchor" href="#依赖框架"><span>依赖框架</span></a></h2><h3 id="爬虫" tabindex="-1"><a class="header-anchor" href="#爬虫"><span>爬虫</span></a></h3><p><a href="https://houbb.github.io/2018/08/19/crawl-jsoup" target="_blank" rel="noopener noreferrer">jsoup</a></p><p><a href="https://github.com/yasserg/crawler4j#quickstart" target="_blank" rel="noopener noreferrer">crawler4j</a></p><h3 id="结果解析" tabindex="-1"><a class="header-anchor" href="#结果解析"><span>结果解析</span></a></h3><p><a href="https://houbb.github.io/tags/#json" target="_blank" rel="noopener noreferrer">json 系列</a></p><p>其中 <a href="https://houbb.github.io/2018/07/20/json-03-jsonpath" target="_blank" rel="noopener noreferrer">jsonpath</a> 在解析的时候非常方便。</p><p><a href="https://houbb.github.io/2018/03/16/okhttp" target="_blank" rel="noopener noreferrer">http 请求</a></p><h2 id="需要注意的点" tabindex="-1"><a class="header-anchor" href="#需要注意的点"><span>需要注意的点</span></a></h2><p>对于抓取的频率+动态ip</p><p>对于失败的重试</p><p>对于抓取的防重复（已经做过的直接跳过）</p><p>js 需要动态获取的内容</p><h2 id="登录" tabindex="-1"><a class="header-anchor" href="#登录"><span>登录</span></a></h2><p>可以参见 <a href="https://github.com/xchaoinfo/fuck-login" target="_blank" rel="noopener noreferrer">fuxk-login</a>，用于抓取登录后的内容。</p><h1 id="xxl-crawler-的特性" tabindex="-1"><a class="header-anchor" href="#xxl-crawler-的特性"><span>xxl-crawler 的特性</span></a></h1><p>1、简洁：API直观简洁，可快速上手；</p><p>2、轻量级：底层实现仅强依赖jsoup，简洁高效；</p><p>3、模块化：模块化的结构设计，可轻松扩展</p><p>4、面向对象：支持通过注解，方便的映射页面数据到PageVO对象，底层自动完成PageVO对象的数据抽取和封装返回；单个页面支持抽取一个或多个PageVO</p><p>5、多线程：线程池方式运行，提高采集效率；</p><p>6、分布式支持：通过扩展 “RunData” 模块，并结合Redis或DB共享运行数据可实现分布式。默认提供LocalRunData单机版爬虫。</p><p>7、JS渲染：通过扩展 “PageLoader” 模块，支持采集JS动态渲染数据。原生提供 Jsoup(非JS渲染，速度更快)、HtmlUnit(JS渲染)、Selenium+Phantomjs(JS渲染，<br> 兼容性高) 等多种实现，支持自由扩展其他实现。</p><p>8、失败重试：请求失败后重试，并支持设置重试次数；</p><p>9、代理IP：对抗反采集策略规则WAF；</p><p>10、动态代理：支持运行时动态调整代理池，以及自定义代理池路由策略；</p><p>11、异步：支持同步、异步两种方式运行；</p><p>12、扩散全站：支持以现有URL为起点扩散爬取整站；</p><p>13、去重：防止重复爬取；</p><p>14、URL白名单：支持设置页面白名单正则，过滤URL；</p><p>15、自定义请求信息，如：请求参数、Cookie、Header、UserAgent轮询、Referrer等；</p><p>16、动态参数：支持运行时动态调整请求参数；</p><p>17、超时控制：支持设置爬虫请求的超时时间；</p><p>18、主动停顿：爬虫线程处理完页面之后进行主动停顿，避免过于频繁被拦截；</p><h1 id="初期设计" tabindex="-1"><a class="header-anchor" href="#初期设计"><span>初期设计</span></a></h1><h2 id="oo" tabindex="-1"><a class="header-anchor" href="#oo"><span>OO</span></a></h2><p>基于 jsoup 抓取页面，配合注解构建为 model。</p><h2 id="fluent-api" tabindex="-1"><a class="header-anchor" href="#fluent-api"><span>fluent-api</span></a></h2><p>基于 fluent-api 设计，优雅配置。</p><h2 id="module-spi" tabindex="-1"><a class="header-anchor" href="#module-spi"><span>module-spi</span></a></h2><p>基于 spi 进行设计，全部可以自行拓展。</p><h2 id="thread" tabindex="-1"><a class="header-anchor" href="#thread"><span>thread</span></a></h2><p>多线程处理</p><h1 id="拓展阅读" tabindex="-1"><a class="header-anchor" href="#拓展阅读"><span>拓展阅读</span></a></h1><p><a href="https://houbb.github.io/2018/08/19/crawl-htmlunit" target="_blank" rel="noopener noreferrer">htmlunit</a></p><h1 id="参考资料" tabindex="-1"><a class="header-anchor" href="#参考资料"><span>参考资料</span></a></h1><p><a href="https://www.xuxueli.com/xxl-crawler/" target="_blank" rel="noopener noreferrer">xxl-crawler</a></p>',59)]))}const l=a(n,[["render",o]]),c=JSON.parse('{"path":"/posts/Crawl/2020-05-05-crawler-01-how-to-design.html","title":"Cralwer-01-如何设计一个爬虫框架","lang":"zh-CN","frontmatter":{"title":"Cralwer-01-如何设计一个爬虫框架","date":"2020-05-05T00:00:00.000Z","categories":["Crawl"],"tags":["crawl","web","sh"],"published":true,"description":"创作背景 其实在此之前，自己也尝试过做过尝试。 而且做了两次，最后因为没有成为一个可高度复用的框架，而逐渐失去维护。 本篇整理下成熟工具的长处，结合自己失败的经验，为设计一款简单灵活的爬虫打下基础。 以前失败的教训 暂停的工具 crawl poseidon 设计理念 为了初期的快速迭代，使用单个模块。 对于页面等，初期不要求。 初期可以只考虑单机，后期...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/blog-backend/posts/Crawl/2020-05-05-crawler-01-how-to-design.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"Cralwer-01-如何设计一个爬虫框架"}],["meta",{"property":"og:description","content":"创作背景 其实在此之前，自己也尝试过做过尝试。 而且做了两次，最后因为没有成为一个可高度复用的框架，而逐渐失去维护。 本篇整理下成熟工具的长处，结合自己失败的经验，为设计一款简单灵活的爬虫打下基础。 以前失败的教训 暂停的工具 crawl poseidon 设计理念 为了初期的快速迭代，使用单个模块。 对于页面等，初期不要求。 初期可以只考虑单机，后期..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-22T03:45:14.000Z"}],["meta",{"property":"article:tag","content":"crawl"}],["meta",{"property":"article:tag","content":"web"}],["meta",{"property":"article:tag","content":"sh"}],["meta",{"property":"article:published_time","content":"2020-05-05T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-22T03:45:14.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"Cralwer-01-如何设计一个爬虫框架\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2020-05-05T00:00:00.000Z\\",\\"dateModified\\":\\"2025-08-22T03:45:14.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1755834314000,"updatedTime":1755834314000,"contributors":[{"name":"binbin.hou","username":"","email":"binbin.hou@huifu.com","commits":1}]},"readingTime":{"minutes":2.73,"words":818},"filePathRelative":"posts/Crawl/2020-05-05-crawler-01-how-to-design.md","localizedDate":"2020年5月5日","excerpt":"\\n<p>其实在此之前，自己也尝试过做过尝试。</p>\\n<p>而且做了两次，最后因为没有成为一个可高度复用的框架，而逐渐失去维护。</p>\\n<p>本篇整理下成熟工具的长处，结合自己失败的经验，为设计一款简单灵活的爬虫打下基础。</p>\\n<h1>以前失败的教训</h1>\\n<h2>暂停的工具</h2>\\n<p><a href=\\"https://github.com/houbb/crawl\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">crawl</a></p>\\n<p><a href=\\"https://github.com/houbb/poseidon.git\\" target=\\"_blank\\" rel=\\"noopener noreferrer\\">poseidon</a></p>","autoDesc":true}');export{l as comp,c as data};
