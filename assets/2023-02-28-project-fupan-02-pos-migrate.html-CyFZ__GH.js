import{_ as p}from"./plugin-vue_export-helper-DlAUqK2U.js";import{c as s,a as e,o as i}from"./app-uJE4P3e0.js";const n={};function t(h,a){return i(),s("div",null,a[0]||(a[0]=[e(`<h1 id="业务背景" tabindex="-1"><a class="header-anchor" href="#业务背景"><span>业务背景</span></a></h1><p>旧的产品线数据：</p><p>三大块：</p><p>（1）控台</p><p>商户、机具、服务商</p><p>（2）交易</p><p>（3）分润</p><hr><p>新的 star 系统：</p><p>包含上面全部功能。</p><p>期望所有的数据从老系统迁移到新系统。</p><h1 id="分步走的迁移策略" tabindex="-1"><a class="header-anchor" href="#分步走的迁移策略"><span>分步走的迁移策略</span></a></h1><h2 id="产品分布" tabindex="-1"><a class="header-anchor" href="#产品分布"><span>产品分布</span></a></h2><p>为减低迁移风险，首先迁移一个最小的产品线 rpos。</p><hr><h2 id="数据继续切分" tabindex="-1"><a class="header-anchor" href="#数据继续切分"><span>数据继续切分</span></a></h2><p>分步走：</p><p>（1）不切交易。只切基本数据。</p><p>首先正向迁移迁移基本信息，保障新控台保障所有旧的数据信息。</p><p>后续的商户进件、服务商进件、机具等全部走新的系统，数据落在新的系统。</p><p>但同时交易没切，为了保证新的用户在老系统正常交易，所以需要把数据反向写到老系统。</p><p>（2）分步骤切交易。</p><p>按照一定比例，比如 1%=&gt;5%=&gt;10%=&gt;30%=&gt;50%=&gt;100%</p><p>逐步切过去，观察没有问题，尽可能降低对于交易的影响。</p><p>（3）最后统一把分润切走。</p><p>分润涉及到出账，风险最高。</p><h1 id="业务梳理" tabindex="-1"><a class="header-anchor" href="#业务梳理"><span>业务梳理</span></a></h1><h2 id="异构" tabindex="-1"><a class="header-anchor" href="#异构"><span>异构</span></a></h2><p>旧的产品线再跑，新的产品线也在跑。</p><p>新产品线业务需求在持续推进，旧的系统基本少有维护，除了一些必要的改造，大家的改动是越小越好。</p><p>正向：负责把旧系统（Oracle）的数据，变成新系统（mysql）新的设计的格式。</p><p>反向：负责把新系统的变动、新的进件，反向写到老系统。保障新用户、数据变化，在旧系统中交易正常、分润正常。</p><p>因为两个系统设计等是有差异的；相同的系统，不同的产品设计也存在差异；所以需要梳理两个系统的表设计和业务关系。</p><h2 id="困难点" tabindex="-1"><a class="header-anchor" href="#困难点"><span>困难点</span></a></h2><p>旧的系统，oracle 的表维护的文档很差，缺少字段注释、设计文档甚至是人员变动比较大。</p><p>整个链路涉及到的研发人员也比较多，需要同时问新旧两个系统的研发：</p><p>（1）商户</p><p>（2）机具</p><p>（3）渠道/代理</p><p>（4）交易</p><p>（5）分润</p><p>几个人整理了很久，整体非常的枯燥，后续只剩下我一个人在处理反向同步。</p><p>接近 100+ 页的梳理文档，几十张表。</p><h1 id="编程部分" tabindex="-1"><a class="header-anchor" href="#编程部分"><span>编程部分</span></a></h1><h2 id="正向" tabindex="-1"><a class="header-anchor" href="#正向"><span>正向</span></a></h2><p>第一次迁移正向是其他小伙伴的。</p><p>整体思路就是通过多线程的方式，把数据迁移到新的系统。</p><p>为了保障知道哪些是迁移数据，便于清理。</p><p>新的系统，表都会额外新增一个 migrate_batch 迁移批次信息。</p><h1 id="反向-设计" tabindex="-1"><a class="header-anchor" href="#反向-设计"><span>反向-设计</span></a></h1><p>反向的话，需要一个触发机制。</p><p>最简单直接的当然是让新系统每次变更，同时把变更通知给反向系统。</p><h2 id="dts" tabindex="-1"><a class="header-anchor" href="#dts"><span>DTS</span></a></h2><p>但是这个对于每一个系统都有开发量，于是采用了基于 mysql DTS 数据变更的监听方式，每一次表发生变更（insert/update/delete），都会触发一次变化，可以基于 DTS，把这个变化的消息放到 kafka 中，反向程序监听 kafka，直接进行相关的操作处理。</p><p>DTS 可以设置关心的具体表，进一步缩小关心的范围。</p><p>DTS 数据库变动数据格式：</p><div class="language-json line-numbers-mode" data-highlighter="shiki" data-ext="json" style="--shiki-light:#383A42;--shiki-dark:#abb2bf;--shiki-light-bg:#FAFAFA;--shiki-dark-bg:#282c34;"><pre class="shiki shiki-themes one-light one-dark-pro vp-code"><code><span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">{</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">&quot;db&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;databaseName&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">// 数据库名称</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">&quot;opType&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;UPDATE&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">// 操作类型</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">&quot;recordTs&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#986801;--shiki-dark:#D19A66;">1596006856</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">, </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">// 变化时间</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">&quot;tb&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: </span><span style="--shiki-light:#50A14F;--shiki-dark:#98C379;">&quot;tableName&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">,  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">//表名称</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">&quot;beforeDataInfo&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">:{}, </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">// 原始的表信息</span></span>
<span class="line"><span style="--shiki-light:#E45649;--shiki-dark:#E06C75;">&quot;dataInfo&quot;</span><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">: {}  </span><span style="--shiki-light:#A0A1A7;--shiki-light-font-style:italic;--shiki-dark:#7F848E;--shiki-dark-font-style:italic;">// 现在的表信息</span></span>
<span class="line"><span style="--shiki-light:#383A42;--shiki-dark:#ABB2BF;">}</span></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="如何不重复、不遗漏-如何保障数据的实时性" tabindex="-1"><a class="header-anchor" href="#如何不重复、不遗漏-如何保障数据的实时性"><span>如何不重复、不遗漏+如何保障数据的实时性</span></a></h2><p>每次变化，都会有一个 recordTS，这个时间是精确到秒的。</p><p>然后老的系统，每一张表都新增了一个 recordTs 字段。</p><p>用于判断数据是否是最新的，超过 recordTs 则丢弃掉对应的消息。</p><p>为了更加准确，每次接收到触发的消息之后，基本采用反查业务只读库的方式。</p><h2 id="数据完整性" tabindex="-1"><a class="header-anchor" href="#数据完整性"><span>数据完整性</span></a></h2><p>有的时候，数据是基于多张表的。</p><p>可能收到一个变化的时候，此时新系统的数据并不完成，可以加一个校验。后续收到时，才进行反查处理。</p><h2 id="数据失败补偿" tabindex="-1"><a class="header-anchor" href="#数据失败补偿"><span>数据失败补偿</span></a></h2><p>DTS 可能会挂掉，kafka 不支持指定的消息重发。</p><p>所以，开放了一个基于 controller 可以触发的补偿任务，可以把失败的消息 json，重新触发一下。</p><h2 id="代码实现层" tabindex="-1"><a class="header-anchor" href="#代码实现层"><span>代码实现层</span></a></h2><p>最简单地方式，是基于 if else 判断，不过不利于代码拓展。</p><p>定义了基于 <code>@TransferRoute</code> 的注解，可以指定对应的 databaseName + dbName + prodId 进行路由。</p><p>prod 产品信息，从 table 中获取。</p><p>给每一个产品，添加了可以开关的配置，便于动态调整。</p><p>给每一张表，统一添加了是否消费的开关，便于调整。</p><h2 id="加解密" tabindex="-1"><a class="header-anchor" href="#加解密"><span>加解密</span></a></h2><p>不同系统对于手机号、身份证等敏感信息的加密策略不同，需要先解密，再加密。</p><h1 id="测试验证" tabindex="-1"><a class="header-anchor" href="#测试验证"><span>测试验证</span></a></h1><h1 id="生产实战" tabindex="-1"><a class="header-anchor" href="#生产实战"><span>生产实战</span></a></h1><h2 id="准备工作" tabindex="-1"><a class="header-anchor" href="#准备工作"><span>准备工作</span></a></h2><p>数据备份，在迁移前，把旧系统的数据全部备份下来。避免数据被反向污染，无从查问题。</p><p>提前准备好条数对比脚本，相关的准备工作，POS 机器等。</p><h2 id="灰度" tabindex="-1"><a class="header-anchor" href="#灰度"><span>灰度</span></a></h2><p>经过多轮生产迁移演练。</p><p>发现问题，修改调整。</p><h2 id="正式迁移" tabindex="-1"><a class="header-anchor" href="#正式迁移"><span>正式迁移</span></a></h2><p>把老系统的所有功能暂停，提前发公告。</p><p>夜里 12:00 开始（业务低峰期）</p><p>正向同步数据：商户+机具+代理+渠道</p><p>数据的验证，条数对比等。在新的系统，查看验证是否正常。</p><p>确认是否正向满足。</p><p>迁移完成后，要保证正向的数据 kafka 已经被丢弃的差不多，然后打开反向开关，测试反向的相关逻辑。</p><h2 id="事后验证" tabindex="-1"><a class="header-anchor" href="#事后验证"><span>事后验证</span></a></h2><p>把遇到的一些问题，尽可能的解决掉。</p><p>基本忙到早晨 9 点，等其他同事过来接班。</p><p>观察 2 天，如果正常，则不进行回滚操作。</p><h2 id="补救刷库" tabindex="-1"><a class="header-anchor" href="#补救刷库"><span>补救刷库</span></a></h2><p>后续使用过程中，发现缺失错误的数据，不断进行刷库处理。</p><p>1 年间，基本刷库 600+ 次。</p><h2 id="成就" tabindex="-1"><a class="header-anchor" href="#成就"><span>成就</span></a></h2><p>一年时间，顺利把 pos 系列迁移完成，且无重大问题。</p><p>保障新老系统的稳定运行。</p><p>==》High</p><h1 id="踩坑指南" tabindex="-1"><a class="header-anchor" href="#踩坑指南"><span>踩坑指南</span></a></h1><h2 id="delete-操作-高危" tabindex="-1"><a class="header-anchor" href="#delete-操作-高危"><span>delete 操作，高危</span></a></h2><p>开始的时候，delete 操作也是监听的。</p><p>后来做了一次表清空，差点把目标表全部清空掉，浪费了测试的时间。</p><p>所以把这个列为高危操作，基本和业务端约定好也没有删除的操作，所以忽略了 delete 操作。</p><h2 id="一秒内并发-反向处理方式-kafka-消息一直没有-ack-多次重复消费" tabindex="-1"><a class="header-anchor" href="#一秒内并发-反向处理方式-kafka-消息一直没有-ack-多次重复消费"><span>一秒内并发，反向处理方式 &amp; kafka 消息一直没有 ack，多次重复消费</span></a></h2><p>recordTs 是一个精确到秒的时间戳。</p><p>有些表的信息，可能一秒内被多次更新，生产就出现了同一秒，数据被丢弃的情况。</p><p>核心问题在于时间不够精确，如果精确到毫秒就好了。</p><p>但是 recordTs 这个字段又没有办法，所以只能修改了当时表的 update_time 作为时间戳，修改了设置的精度。</p><p>测试环境验证过，上线发布之后，发现一个问题，kafka 消费卡主了。当时正值过年，夜里忙到了凌晨 4 点。</p><h3 id="如何解决" tabindex="-1"><a class="header-anchor" href="#如何解决"><span>如何解决</span></a></h3><p>问题的原因在于 kafka 的配置不合理。</p><p>kafka 的触发：生产表比较大，执行完成之后</p><p>kafka 有一个配置项，是批量消费，然后 ack 一个消息，当时设置的量比较大，而且 mer 表变动，涉及的流程很长，导致消费很慢，超时了。</p><p>然后 kafka 不断重试。</p><hr><p>解决方式：首先把当前 mer 表的消息快速丢弃掉，保证其他的消息可以正常消费。</p><p>上线发布：修正对应的配置项，让每一次批量消费的数据量变少，降低重试次数为 3。</p><h3 id="善后" tabindex="-1"><a class="header-anchor" href="#善后"><span>善后</span></a></h3><p>为了尽可能的不影响用户，把 mer 表在事故发生之后，进行重新的 update_time=now() 更新，重新触发一次消费。</p><p>然后如果还有用户反应存在问题，让其尝试业务重新操作，或者帮忙刷库处理。</p><h2 id="故障-扣费-重复收取" tabindex="-1"><a class="header-anchor" href="#故障-扣费-重复收取"><span>故障-扣费 重复收取</span></a></h2><p>确认字段的时候，新系统和老系统的字段是对的。</p><p>但是其实二者的日期格式不同，一个是 yyyyMMdd 的日期，一个是 yyyyMMddHHmmss 的日期。</p><p>结果老系统进行交易，通知更新新系统（不是我参与，不知道），导致新系统的表变化，数据反向，覆盖了老系统的数据，导致格式错误。</p><p>判断是否已经付费时，格式异常，导致需要重新缴费（老系统的健壮性）。</p><p>最核心的问题，还是反向的值错误了。</p><h2 id="问题-消费之后机具需要重新签到" tabindex="-1"><a class="header-anchor" href="#问题-消费之后机具需要重新签到"><span>问题-消费之后机具需要重新签到</span></a></h2><p>和上面类似的原因。</p><h1 id="性能问题-时间成本问题" tabindex="-1"><a class="header-anchor" href="#性能问题-时间成本问题"><span>性能问题-时间成本问题</span></a></h1><p>夜里正向迁移的时候，虽然是一次性的。但是耗时非常的重要。</p><p>希望尽可能的保留更多的时间，用于容错+验证。</p><hr><p>以前商户/机具信息在正向同步的时候，是没有问题的，因为数据量还好，大概几十万，一个小时还能接受。</p><p>第二次同步的时候，迁移的产品比较多，数据量基本接近原来的十多倍，时间过长，无法接收。</p><hr><p>2H=&gt;20H 在夜里迁移是不可接受的。</p><p>尝试了单机提升配置，加线程，不过效果不是很好。</p><p>就把以前的方式否决了。</p><h2 id="v1-基于-dts" tabindex="-1"><a class="header-anchor" href="#v1-基于-dts"><span>v1-基于 DTS</span></a></h2><p>当时选择了旧的 oracle 创建一张新的表，和新的系统表结构一致，加上唯一索引。</p><p>这样，DTS 就可以把 oracle 的表，直接同步到 mysql，且根据唯一索引进行更新。</p><p>所以耗时就变成了两部分：</p><p>1）把数据同步到 oracle 中的新表。</p><p>2）DTS 把新表的数据，同步到目标表。</p><p>第一部分，采用以前的代码方案被否决了。因为商户+机具数据量很大。查出来，处理完，很慢。</p><p>当时发现一种方式，oralce 的 <code>merge into</code> 其实很快，不存在则插入，存在则更新。</p><p>几分钟，可以把一张大表，直接处理完成，且是一个完整的事务，要么同时成功，要么同时失败。</p><p>所以就是往这个方向努力。</p><h3 id="痛苦之处" tabindex="-1"><a class="header-anchor" href="#痛苦之处"><span>痛苦之处</span></a></h3><p>merge into 纯脚本，需要各种 oracle 的 sql 编写。</p><p>1）以前的代码方案被推翻，需要大量的时间+精力重新实现+测试</p><ol start="2"><li>oracle 的 sql 能力自然没有代码这么灵活，比如加密机的调用等就无法处理，需要额外跑批补充。</li></ol><p>3）对数据的要求更高</p><p>代码可以取到结果之后做一些处理，sql 有时候关联存在问题，就不行。</p><p>所以当时又做了一些数据的清理。</p><h2 id="v2-基于时间" tabindex="-1"><a class="header-anchor" href="#v2-基于时间"><span>v2-基于时间</span></a></h2><p>后来考虑到时间的问题。</p><p>采用了提前跑全量，然后跑增量的方式。</p><p>脚本中加入时间的范围限制。</p><p>1）全量，大于一个很小的时间。</p><p>2）增量，大于全量之前一点的时间，避免数据遗漏。</p><p>3）测试脚本，如果是测试的话，可以指定对应的数据，其他保持一致。</p><p>然后全量提前一周跑，分成 3 个晚上，每次处理几千万的数据。</p><p>增量在正式迁移的晚上，停止所有流量入口之后。</p><p>此时增量的数据量不是很大，且当晚进行了一定的提前。</p><h1 id="可以优化的地方" tabindex="-1"><a class="header-anchor" href="#可以优化的地方"><span>可以优化的地方</span></a></h1><h2 id="全量-增量的思想" tabindex="-1"><a class="header-anchor" href="#全量-增量的思想"><span>全量+增量的思想</span></a></h2><p>提前把全量迁移过去，然后再根据变更时间，把增量的迁移过去。</p><p>这种方式，在做大批量的数据迁移非常有用，可以节约很多时间，更加从容。</p><p>如果采用类似的思想，其实先把需要迁移的数据用程序提前跑，然后正式的时候，再跑增量，也未尝不可。</p><h2 id="水平扩展" tabindex="-1"><a class="header-anchor" href="#水平扩展"><span>水平扩展</span></a></h2><p>单个机器的性能，总归是存在瓶颈的。</p><p>不同的商户、机具之间，其实是互相不影响的。</p><p>所以其实可以通过一个生产者+多个消费者。把消息直接均摊到每一个消费者上面，比如 5 台机器，一台 10 个线程，也可以大大的提升同步效率。</p><p>只不过当时被单机-多线程的方式限制了。</p><h1 id="收获" tabindex="-1"><a class="header-anchor" href="#收获"><span>收获</span></a></h1><p>大型系统的迁移，非常的消耗时间和精力。</p><p>需要多个部分的配合协作：</p><p>（1）运营</p><p>安抚用户，发布公告</p><p>（2）产品</p><p>功能验收</p><p>（3）DBA</p><p>提供数据库层的技术支持</p><p>（4）研发+测试</p><p>配合研发+整体的测试流程</p><p>（5）项目带头人</p><p>需要有一个人把这些事情做好，流程顺序非常重要。</p>`,192)]))}const l=p(n,[["render",t]]),o=JSON.parse('{"path":"/posts/Project/2023-02-28-project-fupan-02-pos-migrate.html","title":"项目复盘梳理-02-旧系统数据迁移到新的系统","lang":"zh-CN","frontmatter":{"title":"项目复盘梳理-02-旧系统数据迁移到新的系统","date":"2023-02-13T00:00:00.000Z","categories":["Project"],"tags":["in-actions","project","data-migrate","sh"],"published":false,"description":"业务背景 旧的产品线数据： 三大块： （1）控台 商户、机具、服务商 （2）交易 （3）分润 新的 star 系统： 包含上面全部功能。 期望所有的数据从老系统迁移到新系统。 分步走的迁移策略 产品分布 为减低迁移风险，首先迁移一个最小的产品线 rpos。 数据继续切分 分步走： （1）不切交易。只切基本数据。 首先正向迁移迁移基本信息，保障新控台保障...","head":[["meta",{"property":"og:url","content":"https://houbb.github.io/blog-backend/posts/Project/2023-02-28-project-fupan-02-pos-migrate.html"}],["meta",{"property":"og:site_name","content":"老马啸西风"}],["meta",{"property":"og:title","content":"项目复盘梳理-02-旧系统数据迁移到新的系统"}],["meta",{"property":"og:description","content":"业务背景 旧的产品线数据： 三大块： （1）控台 商户、机具、服务商 （2）交易 （3）分润 新的 star 系统： 包含上面全部功能。 期望所有的数据从老系统迁移到新系统。 分步走的迁移策略 产品分布 为减低迁移风险，首先迁移一个最小的产品线 rpos。 数据继续切分 分步走： （1）不切交易。只切基本数据。 首先正向迁移迁移基本信息，保障新控台保障..."}],["meta",{"property":"og:type","content":"article"}],["meta",{"property":"og:locale","content":"zh-CN"}],["meta",{"property":"og:updated_time","content":"2025-08-22T03:45:14.000Z"}],["meta",{"property":"article:tag","content":"in-actions"}],["meta",{"property":"article:tag","content":"project"}],["meta",{"property":"article:tag","content":"data-migrate"}],["meta",{"property":"article:tag","content":"sh"}],["meta",{"property":"article:published_time","content":"2023-02-13T00:00:00.000Z"}],["meta",{"property":"article:modified_time","content":"2025-08-22T03:45:14.000Z"}],["script",{"type":"application/ld+json"},"{\\"@context\\":\\"https://schema.org\\",\\"@type\\":\\"Article\\",\\"headline\\":\\"项目复盘梳理-02-旧系统数据迁移到新的系统\\",\\"image\\":[\\"\\"],\\"datePublished\\":\\"2023-02-13T00:00:00.000Z\\",\\"dateModified\\":\\"2025-08-22T03:45:14.000Z\\",\\"author\\":[{\\"@type\\":\\"Person\\",\\"name\\":\\"老马啸西风\\",\\"url\\":\\"https://houbb.github.io\\"}]}"]]},"git":{"createdTime":1755834314000,"updatedTime":1755834314000,"contributors":[{"name":"binbin.hou","username":"","email":"binbin.hou@huifu.com","commits":1}]},"readingTime":{"minutes":10.92,"words":3276},"filePathRelative":"posts/Project/2023-02-28-project-fupan-02-pos-migrate.md","localizedDate":"2023年2月13日","excerpt":"\\n<p>旧的产品线数据：</p>\\n<p>三大块：</p>\\n<p>（1）控台</p>\\n<p>商户、机具、服务商</p>\\n<p>（2）交易</p>\\n<p>（3）分润</p>\\n<hr>\\n<p>新的 star 系统：</p>\\n<p>包含上面全部功能。</p>\\n<p>期望所有的数据从老系统迁移到新系统。</p>\\n<h1>分步走的迁移策略</h1>\\n<h2>产品分布</h2>\\n<p>为减低迁移风险，首先迁移一个最小的产品线 rpos。</p>\\n<hr>\\n<h2>数据继续切分</h2>\\n<p>分步走：</p>\\n<p>（1）不切交易。只切基本数据。</p>\\n<p>首先正向迁移迁移基本信息，保障新控台保障所有旧的数据信息。</p>","autoDesc":true}');export{l as comp,o as data};
